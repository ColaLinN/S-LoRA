{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'slora (Python 3.9.20)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n slora ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# parquet_files = glob.glob(\"lmsys-chat-1m/data/*.parquet\")\n",
    "# dataset = Dataset.from_parquet(parquet_files)\n",
    "# df = dataset.to_pandas()\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.columns.tolist())\n",
    "# print(df.head(2))\n",
    "# print(df.shape)\n",
    "# print(df.iloc[0]['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_len_one_turn = df.copy()\n",
    "# df_with_len_one_turn = df_with_len_one_turn[df_with_len_one_turn['turn'] == 1]\n",
    "# print(df_with_len_one_turn.shape)\n",
    "# print(df_with_len_one_turn.head(2))\n",
    "# df_with_len_one_turn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# # Load tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"huggyllama/llama-13b\")\n",
    "# # Ensure a padding token is defined\n",
    "# if tokenizer.pad_token is None:\n",
    "#     if tokenizer.eos_token:\n",
    "#         tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n",
    "#     else:\n",
    "#         tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add a custom pad_token\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Create test data\n",
    "# texts = [\"This is a sample text.\"] * 10000  # Repeat text to simulate batch processing\n",
    "\n",
    "# # Tokenize on CPU\n",
    "# start = time.time()\n",
    "# _ = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# cpu_time = time.time() - start\n",
    "\n",
    "# # Tokenize on GPU\n",
    "# start = time.time()\n",
    "# _ = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "# gpu_time = time.time() - start\n",
    "\n",
    "# print(f\"CPU Time: {cpu_time:.2f} seconds\")\n",
    "# print(f\"GPU Time: {gpu_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import logging\n",
    "# from transformers import AutoTokenizer\n",
    "# from tqdm import tqdm  # 导入 tqdm\n",
    "# import pandas as pd\n",
    "\n",
    "# logging.set_verbosity_error()\n",
    "\n",
    "# # 定义提取长度的函数\n",
    "# def extract_lengths(conversation):\n",
    "#     try:\n",
    "#         if len(conversation) != 2:\n",
    "#             raise ValueError(\"Conversation length must be 2\")\n",
    "\n",
    "#         if conversation[0].get('role') != 'user' or conversation[1].get('role') != 'assistant':\n",
    "#             raise ValueError(\"Invalid roles in conversation: expected 'user' and 'assistant'\")\n",
    "\n",
    "#         user_input = conversation[0].get('content', \"\")\n",
    "#         assistant_output = conversation[1].get('content', \"\")\n",
    "\n",
    "#         len_user_input = len(user_input)\n",
    "#         len_assistant_output = len(assistant_output)\n",
    "#         num_input_tokens = len(tokenizer.encode(user_input))\n",
    "#         num_output_tokens = len(tokenizer.encode(assistant_output))\n",
    "\n",
    "#         return len_user_input, len_assistant_output, num_input_tokens, num_output_tokens\n",
    "#     except Exception as e:\n",
    "#         raise RuntimeError(f\"Error in processing conversation: {e}\")\n",
    "\n",
    "# # 加载分词器\n",
    "# print('Loading tokenizer...')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"huggyllama/llama-13b\")\n",
    "\n",
    "# # 显示进度条并处理 DataFrame\n",
    "# print('Processing conversations...')\n",
    "# tqdm.pandas()  # 激活 tqdm 对 Pandas 的支持\n",
    "\n",
    "# df_with_len_one_turn[['input_len', 'output_len', 'num_input_tokens', 'num_output_tokens']] = df_with_len_one_turn['conversation'].progress_apply(\n",
    "#     lambda x: pd.Series(extract_lengths(x))\n",
    "# )\n",
    "\n",
    "# # 打印前几行结果\n",
    "# df_with_len_one_turn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_with_len_one_turn.describe())\n",
    "# df_with_len_one_turn.to_csv('df_with_len_one_turn.csv', index=True)\n",
    "\n",
    "df_with_len_one_turn = pd.read_csv('df_with_len_one_turn.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入\n",
    "mean_value = df_with_len_one_turn['num_input_tokens'].mean()\n",
    "median_value = df_with_len_one_turn['num_input_tokens'].median()\n",
    "mode_value = df_with_len_one_turn['num_input_tokens'].mode()[0]  # 可能有多个众数，取第一个\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df_with_len_one_turn['num_input_tokens'], bins=np.logspace(0, 4, num=10000), edgecolor='black', alpha=0.7)\n",
    "plt.xscale('linear')\n",
    "plt.xticks([10**i for i in range(4)], [f'10^{i}' for i in range(4)])  # 设置显示的刻度和标签\n",
    "plt.xlim(1, 10**4)\n",
    "plt.axvline(mean_value, color='blue', linestyle='--', linewidth=1.5, label=f'Mean ({mean_value:.2f})')\n",
    "plt.axvline(median_value, color='green', linestyle='--', linewidth=1.5, label=f'Median ({mean_value:.2f})')\n",
    "plt.axvline(mode_value, color='orange', linestyle='--', linewidth=1.5, label=f'Mode ({mode_value})')\n",
    "plt.xlabel('Number of Input Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Input Tokens')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "mean_value = df_with_len_one_turn['num_output_tokens'].mean()\n",
    "median_value = df_with_len_one_turn['num_output_tokens'].median()\n",
    "mode_value = df_with_len_one_turn['num_output_tokens'].mode()[0]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df_with_len_one_turn['num_output_tokens'], bins=np.logspace(0, 4, num=100), edgecolor='black', alpha=0.7)\n",
    "plt.xscale('linear')\n",
    "plt.xticks([10**i for i in range(4)], [f'10^{i}' for i in range(4)])  # 设置显示的刻度和标签\n",
    "plt.xlim(1, 10**4)\n",
    "plt.axvline(mean_value, color='blue', linestyle='--', linewidth=1.5, label=f'Mean ({mean_value:.2f})')\n",
    "plt.axvline(median_value, color='green', linestyle='--', linewidth=1.5, label=f'Median ({mean_value:.2f})')\n",
    "plt.axvline(mode_value, color='orange', linestyle='--', linewidth=1.5, label=f'Mode ({mode_value})')\n",
    "plt.xlabel('Num of Output Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Output Tokens with Mean and Mode')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
