[('num_adapters', 0), ('alpha', 1), ('req_rate', 2), ('cv', 1), ('duration', 15), ('input_range', [1, 5]), ('output_range', [1, 5])]
get_adapter_dirs input and output 0 ['dummy-lora-13b-rank-64', 'dummy-lora-13b-rank-32', 'dummy-lora-13b-rank-16'] None ['dummy-lora-13b-rank-64-0', 'dummy-lora-13b-rank-32-0', 'dummy-lora-13b-rank-16-0']
========
generating requests v2 1 1 2 1 15 [1, 5] [1, 5] [('huggyllama/llama-13b', None)] 42
avg_len: 646.5 avg_prompt_len: 384.5 avg_output_len: 262.0
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12240
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 6144
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12
req_id 1 prompt_len 1024 output_len 8 request_latency 0.39 s, first_token_latency 0.18 s
req_id 2 prompt_len 2 output_len 8 request_latency 0.71 s, first_token_latency 0.50 s
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12
req_id 3 prompt_len 2 output_len 8 request_latency 0.31 s, first_token_latency 0.10 s
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12
req_id 4 prompt_len 2 output_len 8 request_latency 0.28 s, first_token_latency 0.07 s
ready to request generate API http://localhost:8000/generate_stream model_dir huggyllama/llama-13b adapter_dir None len_prompt 12
req_id 5 prompt_len 2 output_len 8 request_latency 0.50 s, first_token_latency 0.29 s
req_id 7 prompt_len 2 output_len 8 request_latency 0.29 s, first_token_latency 0.09 s
req_id 6 prompt_len 2 output_len 8 request_latency 0.40 s, first_token_latency 0.19 s
req_id 0 prompt_len 2040 output_len 2040 request_latency 61.04 s, first_token_latency 0.28 s
Total time: 61.50 s
Aborted Request: 0
Throughput: 0.13 requests/s
Throughput strip: -0.77 requests/s
Average latency: 7.99 s
Average latency per token: 0.03 s
Average latency per output token: 0.05 s
Average first token latency: 0.21 s
90 percentile first token latency: < 0.35 s
50 percentile first token latency: < 0.18 s
Average satisfaction: 1.00
90 percentile satisfaction: > 1.00
50 percentile satisfaction: > 1.00
Average attainment: 1.00
